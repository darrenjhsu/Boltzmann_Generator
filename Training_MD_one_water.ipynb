{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4a6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/OpenMM_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/OpenMM_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/OpenMM_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/OpenMM_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/OpenMM_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/OpenMM_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from simtk.openmm.app import *\n",
    "from simtk.openmm import *\n",
    "from simtk.unit import *\n",
    "from sys import stdout\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import hoomd.htf as htf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from deep_boltzmann.networks.invertible import InvNet\n",
    "from deep_boltzmann.networks.invertible import split_merge_indices, SplitChannels, MergeChannels, \\\n",
    "                                               RealNVP, NICER, InvNet, nonlinear_transform, Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa2f1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum likelihood in z\n",
    "def loss_z(inv_net):\n",
    "    return -inv_net.log_likelihood_z_normal()\n",
    "\n",
    "def loss_x(inv_net):\n",
    "    x = inv_net.output_x\n",
    "    f = inv_net.overlap_model.PotentialEnergy(x)\n",
    "    #return tf.where(f>0,tf.math.log(f)-inv_net.log_det_Jzx[:,0],0)\n",
    "    #return f*tf.math.exp(-inv_net.log_det_Jzx[:,0])\n",
    "    return f-inv_net.log_det_Jzx[:,0]\n",
    "    #return f*tf.math.exp(-inv_net.log_det_Jzx[:,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20342091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverlapInvNet(InvNet):\n",
    "\n",
    "    def __init__(self, overlap_model, layers):\n",
    "        \"\"\" Invertible net where we have an overlap function (==0 or 1) that defines p(x)\n",
    "            and the prior is the uniform on the interval [a,b)\"\"\"\n",
    "        self.overlap_model = overlap_model\n",
    "        super().__init__(overlap_model.dim, layers, prior='normal')\n",
    "        \n",
    "        self.Tzx.add_loss(loss_x(self))\n",
    "        self.Txz.add_loss(loss_z(self))\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, filename, energy_model):\n",
    "        \"\"\" Loads parameters into model. Careful: this clears the whole TF session!!\n",
    "        \"\"\"\n",
    "        from deep_boltzmann.util import load_obj\n",
    "        keras.backend.clear_session()\n",
    "        D = load_obj(filename)\n",
    "        layerdicts = D['layers']\n",
    "        layers = [eval(d['type']).from_dict(d) for d in layerdicts]\n",
    "        return EnergyInvNet(energy_model, layers, prior=prior)\n",
    "\n",
    "    def weight(self):\n",
    "        \"\"\" Computes the reweighting factor\n",
    "        \"\"\"\n",
    "        z = self.input_z\n",
    "        x = self.output_x\n",
    "        # compute overlap property\n",
    "        f = self.overlap_model.smooth_overlap_tf(x)\n",
    "        weight = tf.math.exp(self.log_det_Jzx[:, 0])\n",
    "        return weight\n",
    "\n",
    "    def sample(self, nsample=100000, temperature=1.0):\n",
    "        \"\"\" Samples from prior distribution in z and produces generated x configurations\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        temperature : float\n",
    "            Relative temperature. Equal to the variance of the isotropic Gaussian sampled in z-space.\n",
    "        nsample : int\n",
    "            Number of samples\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        sample_z : array\n",
    "            Samples in z-space\n",
    "        sample_x : array\n",
    "            Samples in x-space\n",
    "        weight_z:\n",
    "            Weight of z samples\n",
    "        overlap_x : array\n",
    "            Overlap property of x samples\n",
    "        w : array\n",
    "            Weight of samples\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        sample_z, energy_z = self.sample_z(nsample=nsample, return_energy=True, temperature=temperature)\n",
    "\n",
    "        sample_x, Jzx = self.transform_zxJ(sample_z)\n",
    "        overlap_x = self.overlap_model.smooth_overlap_tf(sample_x).numpy()\n",
    "        print(overlap_x)\n",
    "        w = np.exp(Jzx)\n",
    "        logw = overlap_x + energy_z + Jzx\n",
    "\n",
    "        return sample_z, sample_x, energy_z, overlap_x, w, logw\n",
    "\n",
    "    \n",
    "    def train_z(self, x, xval=None, optimizer=None, lr=0.001, epochs=2000, batch_size=1024, verbose=1, clipnorm=None):\n",
    "        if optimizer is None:\n",
    "            if clipnorm is None:\n",
    "                optimizer = keras.optimizers.Adam(lr=lr)\n",
    "            else:\n",
    "                optimizer = keras.optimizers.Adam(lr=lr, clipnorm=clipnorm)\n",
    "                \n",
    "        self.Txz.compile(optimizer)\n",
    "\n",
    "        if xval is not None:\n",
    "            validation_data = (xval, np.zeros_like(xval))\n",
    "        else:\n",
    "            validation_data = None\n",
    "\n",
    "        hist = self.Txz.fit(x=x, validation_data=validation_data,\n",
    "                            batch_size=batch_size, epochs=epochs, verbose=verbose, shuffle=True)\n",
    "\n",
    "        return hist\n",
    "    \n",
    "    def train_x(self, optimizer=None, lr=0.001, batches=1,epochs=2000, batch_size=1024, verbose=1, clipnorm=None):\n",
    "        if optimizer is None:\n",
    "            if clipnorm is None:\n",
    "                optimizer = keras.optimizers.Adam(lr=lr)\n",
    "            else:\n",
    "                optimizer = keras.optimizers.Adam(lr=lr, clipnorm=clipnorm)\n",
    "                \n",
    "        self.Tzx.compile(optimizer)\n",
    "\n",
    "        x = self.sample_z(nsample=batches*batch_size, return_energy=False)\n",
    "        hist = self.Tzx.fit(x=x,batch_size=batch_size, epochs=epochs, verbose=verbose, shuffle=True)\n",
    "\n",
    "        return hist\n",
    "\n",
    "    def train_both(self, x, xval=None, optimizer=None, lr=0.001, epochs=2000, batch_size=1024, verbose=1, clipnorm=None):\n",
    "        if optimizer is None:\n",
    "            if clipnorm is None:\n",
    "                optimizer = keras.optimizers.Adam(lr=lr)\n",
    "            else:\n",
    "                optimizer = keras.optimizers.Adam(lr=lr, clipnorm=clipnorm)\n",
    "       \n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        losses = []\n",
    "        losses.append(loss_z(self))\n",
    "        losses.append(loss_x(self))\n",
    "        inputs.append(self.input_x)\n",
    "        inputs.append(self.input_z)\n",
    "        outputs.append(self.output_z)\n",
    "        outputs.append(self.output_x)\n",
    "\n",
    "        self.model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "        l = losses[0]+losses[1]\n",
    "        self.model.add_loss(l)\n",
    "        self.model.compile(optimizer=optimizer)\n",
    "        \n",
    "        if xval is not None:\n",
    "            validation_data = (xval, np.zeros_like(xval))\n",
    "        else:\n",
    "            validation_data = None\n",
    "\n",
    "        w = self.sample_z(nsample=x.shape[0], return_energy=False)\n",
    "        hist = self.model.fit(x=[x,w], validation_data=validation_data,\n",
    "                            batch_size=batch_size, epochs=epochs, verbose=verbose, shuffle=True)\n",
    "\n",
    "        return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a955d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Limit(object):\n",
    "    def __init__(self, dim, L=1):\n",
    "        self.L = L\n",
    "        self.dim = dim\n",
    "    \n",
    "        self.tanh = tf.keras.layers.Activation('tanh')\n",
    "        self.scale = tf.keras.layers.experimental.preprocessing.Rescaling(scale=self.L/2)\n",
    "        self.inv_scale = tf.keras.layers.experimental.preprocessing.Rescaling(scale=2/self.L)\n",
    "        self.atanh = tf.keras.layers.Activation(lambda x: tf.atanh(x))\n",
    "        \n",
    "    def connect_xz(self, x):\n",
    "        def lambda_Jxz(x):\n",
    "            J = -tf.math.log(1-(2*x/self.L)**2)\n",
    "            return tf.reduce_sum(J,axis=-1)[0] * tf.ones((tf.shape(x)[0], 1))\n",
    "        self.log_det_xz = keras.layers.Lambda(lambda_Jxz)(x)\n",
    "        z = self.atanh(self.inv_scale(x))\n",
    "        return z\n",
    "\n",
    "    def connect_zx(self, z):\n",
    "        def lambda_Jzx(z):\n",
    "            J = -tf.math.log(tf.cosh(z)**2)\n",
    "            return tf.reduce_sum(J,axis=-1)[0] * tf.ones((tf.shape(z)[0], 1))\n",
    "        self.log_det_zx = keras.layers.Lambda(lambda_Jzx)(z)\n",
    "        x = self.scale(self.tanh(z))\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def log_det_Jxz(self):\n",
    "        \"\"\" Log of |det(dz/dx)| for the current batch. Format is batchsize x 1 or a number \"\"\"\n",
    "        return self.log_det_xz\n",
    "\n",
    "    @property\n",
    "    def log_det_Jzx(self):\n",
    "        \"\"\" Log of |det(dx/dz)| for the current batch. Format is batchsize x 1 or a number \"\"\"\n",
    "        return self.log_det_zx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c220bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invnet(dim, layer_types, overlap_model=None, channels=None, L=1.0,\n",
    "           nl_layers=2, nl_hidden=100, nl_activation='relu',\n",
    "           nl_activation_t='relu',scale=None, prior='normal'):\n",
    "    \"\"\"\n",
    "    layer_types : str\n",
    "        String describing the sequence of layers. Usage:\n",
    "            N NICER layer\n",
    "            R RealNVP layerl\n",
    "            S Scaling layer\n",
    "        Splitting and merging layers will be added automatically\n",
    "    overlap_model : Overlap model class\n",
    "        Class with overlap_tf() and dim\n",
    "    channels : array or None\n",
    "        Assignment of dimensions to channels (0/1 array of length ndim)\n",
    "    nl_layers : int\n",
    "        Number of hidden layers in the nonlinear transformations\n",
    "    nl_hidden : int\n",
    "        Number of hidden units in each nonlinear layer\n",
    "    nl_activation : str\n",
    "        Activation functions used in the nonlinear layers\n",
    "    scale : None or float\n",
    "        If a scaling layer is used, fix the scale to this number. If None, scaling layers are trainable\n",
    "    \"\"\"\n",
    "    # fix channels\n",
    "    channels, indices_split, indices_merge = split_merge_indices(dim, nchannels=2, channels=channels)\n",
    "\n",
    "    # augment layer types with split and merge layers\n",
    "    split = False\n",
    "    tmp = ''\n",
    "    for ltype in layer_types:\n",
    "        if (ltype == 'S' or ltype == 'L') and split:\n",
    "            tmp += '>'\n",
    "            split = False\n",
    "        if (ltype == 'N' or ltype == 'R') and not split:\n",
    "            tmp += '<'\n",
    "            split = True\n",
    "        tmp += ltype\n",
    "    if split:\n",
    "        tmp += '>'\n",
    "    layer_types = tmp\n",
    "    print(layer_types)\n",
    "\n",
    "    # prepare layers\n",
    "    layers = []\n",
    "\n",
    "#     reg = tf.keras.regularizers.l2(.01) #?\n",
    "    reg = None\n",
    "    for ltype in layer_types:\n",
    "        if ltype == '<':\n",
    "            # split into two x channels\n",
    "            layers.append(SplitChannels(dim, nchannels=2, channels=channels))\n",
    "        if ltype == '>':\n",
    "            # merge into one z channel\n",
    "            layers.append(MergeChannels(dim, nchannels=2, channels=channels))\n",
    "        if ltype == 'N':\n",
    "            M1 = nonlinear_transform(indices_split[1].size, nlayers=nl_layers, nhidden=nl_hidden,\n",
    "                                     activation=nl_activation)\n",
    "            M2 = nonlinear_transform(indices_split[0].size, nlayers=nl_layers, nhidden=nl_hidden,\n",
    "                                     activation=nl_activation)\n",
    "            layers.append(NICER([M1, M2]))\n",
    "        elif ltype == 'R':\n",
    "            S1 = nonlinear_transform(indices_split[1].size, nlayers=nl_layers, nhidden=nl_hidden,\n",
    "                                     activation=nl_activation, init_outputs=0,\n",
    "                                     activity_regularizer=reg)\n",
    "            T1 = nonlinear_transform(indices_split[1].size, nlayers=nl_layers, nhidden=nl_hidden,\n",
    "                                     activation=nl_activation_t)\n",
    "            S2 = nonlinear_transform(indices_split[0].size, nlayers=nl_layers, nhidden=nl_hidden,\n",
    "                                     activation=nl_activation, init_outputs=0,\n",
    "                                     activity_regularizer=reg)\n",
    "            T2 = nonlinear_transform(indices_split[0].size, nlayers=nl_layers, nhidden=nl_hidden,\n",
    "                                     activation=nl_activation_t)\n",
    "            layers.append(RealNVP([S1, T1, S2, T2]))\n",
    "        elif ltype == 'L':\n",
    "            layers.append(Limit(dim, L=L))\n",
    "        elif ltype == 'S':\n",
    "            # scaling layer\n",
    "            if scale is None:\n",
    "                scaling_factors = None\n",
    "            else:\n",
    "                scaling_factors = scale * np.ones((1, dim))\n",
    "            layers.append(Scaling(dim, scaling_factors=scaling_factors, trainable=(scale is None)))\n",
    "\n",
    "    if overlap_model is None:\n",
    "        inv_net = InvNet(dim, layers, prior='normal')\n",
    "    else:\n",
    "        inv_net = OverlapInvNet(overlap_model, layers)\n",
    "    \n",
    "    inv_net.reg = reg\n",
    "    return inv_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "525f95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneWaterTest(object):\n",
    "    def __init__(self,N):\n",
    "        \"\"\" N: number of particles\n",
    "            L: Box length\n",
    "            sigma: Particle size\"\"\"\n",
    "        self.N = N\n",
    "        self.dim = 3*self.N # dim = 2\n",
    "        pdb = PDBFile('water.pdb')\n",
    "        self.forcefield = ForceField('amber14-all.xml', 'amber14/tip3pfb.xml')\n",
    "        self.modeller = Modeller(pdb.topology, pdb.positions)\n",
    "        # modeller.deleteWater()\n",
    "        self.modeller.addHydrogens(self.forcefield)\n",
    "\n",
    "        self.system = self.forcefield.createSystem(self.modeller.topology, nonbondedMethod=NoCutoff, \n",
    "                                                   constraints=None, rigidWater=False)\n",
    "        # modeller.positions[0] = Quantity(Vec3(0,0,0), unit=nanometer)\n",
    "        self.integrator = LangevinMiddleIntegrator(300*kelvin, 1/picosecond, 0.004*picoseconds)\n",
    "        self.simulation = Simulation(self.modeller.topology, self.system, self.integrator)\n",
    "        self.simulation.context.setPositions(self.modeller.positions)\n",
    "        # print(pdb.positions)\n",
    "        self.state = self.simulation.context.getState(getEnergy=True)\n",
    "        self.energy = self.state.getPotentialEnergy()\n",
    "        print(self.energy)\n",
    "        \n",
    "    def PotentialEnergy(self, x=None):\n",
    "        # x has to be an 2D array of 6*3\n",
    "        if x is not None:\n",
    "            print(f'x is not None')\n",
    "            temp_positions = [None]*self.N\n",
    "            for ii in range(self.N):\n",
    "                xi = x[ii]\n",
    "                temp_positions[ii] = Quantity(Vec3(xi[0], xi[1], xi[2]), unit=nanometer)\n",
    "            print(temp_positions)\n",
    "            self.simulation.context.setPositions(temp_positions)\n",
    "            \n",
    "            self.state = self.simulation.context.getState(getEnergy=True,getPositions=True)\n",
    "            self.energy = self.state.getPotentialEnergy()\n",
    "            print(self.state.getPositions())\n",
    "\n",
    "        return self.energy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56dd6ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.309070587158203 kJ/mol\n"
     ]
    }
   ],
   "source": [
    "Water = OneWaterTest(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bc01469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is not None\n",
      "[Quantity(value=Vec3(x=0, y=0, z=0), unit=nanometer), Quantity(value=Vec3(x=0, y=1, z=0), unit=nanometer), Quantity(value=Vec3(x=1, y=1, z=0), unit=nanometer)]\n",
      "[Vec3(x=0.0, y=0.0, z=0.0), Vec3(x=0.0, y=1.0, z=0.0), Vec3(x=1.0, y=1.0, z=0.0)] nm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "586334.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Water.PotentialEnergy(x=[[0,0,0],[0,1,0],[1,1,0]]) / kilojoule_per_mole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b4fa4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(x):\n",
    "    return -tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dd36f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RRRR>\n",
      "x is not None\n",
      "[Quantity(value=Vec3(x=<KerasTensor: shape=() dtype=float32 (created by layer 'tf.__operators__.getitem_11')>, y=<KerasTensor: shape=() dtype=float32 (created by layer 'tf.__operators__.getitem_12')>, z=<KerasTensor: shape=() dtype=float32 (created by layer 'tf.__operators__.getitem_13')>), unit=nanometer), Quantity(value=Vec3(x=<KerasTensor: shape=() dtype=float32 (created by layer 'tf.__operators__.getitem_15')>, y=<KerasTensor: shape=() dtype=float32 (created by layer 'tf.__operators__.getitem_16')>, z=<KerasTensor: shape=() dtype=float32 (created by layer 'tf.__operators__.getitem_17')>), unit=nanometer), Quantity(value=Vec3(x=<KerasTensor: shape=() dtype=float32 (created by layer 'tf.__operators__.getitem_19')>, y=<KerasTensor: shape=() dtype=float32 (created by layer 'tf.__operators__.getitem_20')>, z=<KerasTensor: shape=() dtype=float32 (created by layer 'tf.__operators__.getitem_21')>), unit=nanometer)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in method Context_setPositions, argument 2 could not be converted to type std::vector< Vec3,std::allocator< Vec3 > > const &",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-60ca3c2fca6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m bg = invnet(Water.dim, 'RRRR', overlap_model=Water, nl_layers=2, nl_hidden=10, #200, #100\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#            nl_activation='tanh', nl_activation_t='tanh', L=L)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m            nl_activation='tanh', nl_activation_t='relu')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-4ef99b763b3c>\u001b[0m in \u001b[0;36minvnet\u001b[0;34m(dim, layer_types, overlap_model, channels, L, nl_layers, nl_hidden, nl_activation, nl_activation_t, scale, prior)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0minv_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0minv_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOverlapInvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlap_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0minv_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bcb40007be28>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, overlap_model, layers)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTzx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTxz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9c702fc80f83>\u001b[0m in \u001b[0;36mloss_x\u001b[0;34m(inv_net)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverlap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPotentialEnergy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#return tf.where(f>0,tf.math.log(f)-inv_net.log_det_Jzx[:,0],0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#return f*tf.math.exp(-inv_net.log_det_Jzx[:,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-1cd5177a2b28>\u001b[0m in \u001b[0;36mPotentialEnergy\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mtemp_positions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuantity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVec3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnanometer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_positions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetPositions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_positions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetEnergy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgetPositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/OpenMM_env/lib/python3.7/site-packages/simtk/openmm/openmm.py\u001b[0m in \u001b[0;36msetPositions\u001b[0;34m(self, positions)\u001b[0m\n\u001b[1;32m   2423\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mwhose\u001b[0m \u001b[0mlength\u001b[0m \u001b[0mequals\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparticles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m'th element contains the position of the i'\u001b[0m\u001b[0mth\u001b[0m \u001b[0mparticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m         \"\"\"\n\u001b[0;32m-> 2425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_openmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContext_setPositions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetVelocities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvelocities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in method Context_setPositions, argument 2 could not be converted to type std::vector< Vec3,std::allocator< Vec3 > > const &"
     ]
    }
   ],
   "source": [
    "# reset model\n",
    "#bg = invnet(model.dim, 'LRRRRRRRRRRRR', overlap_model=model, nl_layers=4, nl_hidden=200, #100\n",
    "bg = invnet(Water.dim, 'RRRR', overlap_model=Water, nl_layers=2, nl_hidden=10, #200, #100\n",
    "#            nl_activation='tanh', nl_activation_t='tanh', L=L)\n",
    "           nl_activation='tanh', nl_activation_t='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d80b51d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(Water.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb14016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
